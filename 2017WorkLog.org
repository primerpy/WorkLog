
* 2017-Work-Log
  My work log for 2017

* 2017-March-April-log
  
  Work log for march 2017

** Date:<2017-03-01 Wed>

*** Emacs Training
    - A good selection of video tutorials for emacs, linux etc.
      https://www.youtube.com/playlist?list=PLEB9CCD61FA858FC5
    - A good github.
      https://github.com/emacs-tw/emacs-101

**** Create a table
     | Col1  | Col2   |
     | item1 | value1 |

**** Checklist
     - [ ] This is a checklist entry
     - [X] C-c C-c toggles through things

**** Insert a date
     - C-c . <2017-03-01 Wed>

**** Source Code Blocks
#+BEGIN_SRC python :results output
import numpy as np
#+END_SRC

#+RESULTS:

** Date:<2017-03-02 Thu>

*** DONE Todos
    SCHEDULED: <2017-03-02 Thu>
    - [X] Excel Macro Check AVA Model (Find a solution to empty oject for each loop)
    - [X] Demo Swedes
    - [X] SQLite set up and uploading

*** Emacs Learning
    - an awesome forum from TW: https://emacser.tw/
    - Emacs 101: https://github.com/emacs-tw/emacs-101

** Date:<2017-03-03 Fri>


*** 

*** SQLite
    - [ ] 
    - [ ] 
    - 
    - 
*** Good Data Science Sites
    - http://chrisalbon.com/
    - https://www.r-bloggers.com/
*** Emacs Learning
    - Orgmode: http://orgmode.org/manual/Plain-lists
    - M-Ret: insert a bullet
    - [ ] M-Shift-Ret insert a todo

** Date:<2017-03-04 Sat>
*** Weigh-in: 272
*** Jupyter notebook
    - [ ] Control then m then l will show line numbers in the jupyter cell 
** Date:<2017-03-06 Mon>
*** Steps to git overwirte local files
    - [ ] git fetch origin master
    - [ ] git reset --hard FETCH_HEAD
    - [ ] git clean -df

** Date:<2017-03-09 Thu>
*** Class, Attributes, Method
    - [ ] Create a class
    - [ ] Attributes:
    - [ ] Methods:
      - [ ] __init__(self)
** Date:<2017-03-10 Fri> 
*** Project Organization
    - [ ] AVA Model
      - [ ] Database: SQLite Youtube
      - [ ] Modeling: Start Building
      - [ ] Web App Framework: Django Udemy
      - [ ] Python Mid-end: Data Science Python Udemy
      - [ ] Python Mid-end: Machine Learning Bootcamp Udemy
      - [ ] Front-end: Web development Udemy/Free Code Academy
      - [ ] Model update: VBA
    - [ ] Udacity Deep Learning
      - [ ] Review all materials again
      - [ ] Python Fundamentals: Pluralsight + Lynda
      - [ ] C++ Prep: Pluralsight + Lynda
    - [ ] acebigdata
      - [ ] Review Pelican Process
      - [ ] Organize Github
      - [ ] Organize blog
    - [ ] pomodorocoder
      - [ ] Make first series: SQLite with Python
    - [ ] Other Data Science
      - [ ] DataCamp
      - [ ] Standford Machine Learning: Octave
      - [ ] Toronto Uiversity Nueral Network:  Octave
      - [ ] Analytical Edge
      - [ ] Udemy
*** SQLite
    - [ ] SQLite Part1
    - [ ] SQLite Part2
    - [ ] SQLite Part3
      - [ ] SQLite Rules
	- [ ] Commands end with semicolon ";"
	- [ ] 3 Types of Values: string, numeric, binary
	- [ ] 5 Types in SQLite: integer, real, text, blob, Null
	- [ ] Case insensitive
	- [ ] Single Line Comments --
	- [ ] Multiline Comments /**/
	- [ ] 1 Primary Key
      - [ ] 
    - [ ] SQLite Part4
** Date:<2017-03-11 Sat> 
*** Store Github login and password
    - [ ] create a text file: ~/.netrc
    - [ ] in the file type in the following:
          machine github.com
	      login <user>
	      password <password>
    - [ ] Can also run the following command
      - [ ] $ git config credential.helper store
      - [ ] $ git push https://github.com/repo.git
      - [ ] Username for 'https://github.com': <USERNAME>
      - [ ] Password for 'https://USERNAME@github.com': <PASSWORD>
*** Install Cuda on Ubuntu 16.04
    - [ ]

** Date:<2017-03-14 Tue>

*** Django
**** Create first django project
     - [ ] Open up Atom Text Editor
     - [ ] Open command line terminal
     - [ ] Activate the Virtual Environment: activate myDjango
     - [ ] Create first project: adjango-admin startproject first_project
       - [ ] 
     - [ ] 

** Date:<2017-03-15 Wed>
*** AVA model
    - [ ] Use pandas read all excel files
** Date:<2017-03-23 Thu>
*** Django Notes
    - [X] Create Virtual Environment
      - [X] conda create --name "env name" django
      - [X] conda info --envs (check available env names)
      - [X] source activate "env name"
    - [X] Create Django Project
      - [X] django-admin
      - [X] django-admin startproject "project name"
    - [X] Run server
      - [X] cd to project folder
      - [X] python manage.py runserver
    - [X] Create Django Application
      - [X] python manage.py startapp "app name"
    - [X] Create a View and Map to a URL
      - [X] Got to "project folder" and setting.py file
      - [X] find "INSTALLED_APPS" add "app name"
      - [X] find view.py file, create index function
      - [X] import view and index function to urls.py file
      - [X] Map the view and index function to urls.py so that the link to view can be created
    - [X] Self Challenge
      - [X] Create a new project called "ProTwo": django-admin startproject ProTwo
      - [X] Create a new app called "AppTwo": cd ProTwo, then python manage.py startapp AppTwo
      - [X] Create view index function <em>This is app2</em>
      - [X] Map view correctly to urls.py
      - [X] Things to note
	- [X] Don't forget to add app in the settings.py file
	- [X] in url.py file, don't forget name =
    - [X] URL mapping, the purpose is to keep urls.py file clean and modular
      - [X] include() function from django.conf.urls
      - [X] add regular expression url('r^first_project/',)
      - [X] regular expression term should match django application name

** Date:<2017-03-24 Fri>
*** Django Notes
    - [X] Django Templates
      - [X] Create a template directory
      - [X] Create subdirectory for each specific app templates
      - [X] Such as "first_project/templates/first_app"
      - [X] use Python's os module to dynamically generate the correct file path strings
	- [X] print(__file__)
	- [X] print(os.paht.dirname(__file__))
      - [X] let Django know of the templates by editing the DIR key inside of the templates dictionary in the settings.py file
	- [X] use TEMPLATE_DIR = os.path.join(BASE_DIR, "templates"), note DO NOT use plus '+' sign
	- [X] In settings file, find TEMPLATES and in 'DIR' enter TEMPLATE_DIR
      - [X] Create index.html file inside of the templates/first_app directory
	- [X] Inside this HTML file, we will insert template tags (Django Template Variables. These tags will allow us to inject CONTENTS into the HTML directly from Django
	- [X] Django will be able to inject content into the HTML, use Python code to inject content from a database!
	  - [X] {{insert_me}}
	  - [X] connect insert_me with django, via editing views.py
      - [X] Gotcha moment
	- [X] app folder contains views.py: mid end python
	- [X] templates folder contains index.html: front end codes: HTML+CSS+JS
	- [X] in index.html file, use Django tags to connect with views.py file
	- [X] build index(request) function in views.py file to "render" Django tags and realize the connection
** Date:<2017-03-25 Sat>
*** D3 Notes
    - [X] Refresher
      - [X] HTML5
      - [X] SVG: Scalable Vector Graphics
	- [X] SVG tags sit in body tags or div tags
	- [X] SVG can only contain graphical elements
	- [X] D3 adds graphics and text to SVG element and binds data to those elements
	- [X] Vector vs. Raster/bitmap
	  - [X] Vector: never lose definition, perfect for my purpose, drawing lines, shapes and fills
	  - [X] Bitmap: photos composed of small pixels
      - [X] CSS
	- [X] handling clashes of styles: more specific definition will be used
      - [X] JS
	- [X] browsers must load the D3 file before it loads shapes.js 
      - [X] DOM
*** Bokeh
    - [ ] conda install bokeh
    - [ ] 
*** Flask Notes
    - [X] Docker
      - [X] docker-compose up
      - [X] docker-compose stop
      - [X] docker-compose rm -f
      - [X] docker rmi -f $(docker images -qf dangling=true)
    - [X] Install Flask Dependencies
      - [X] from flask import Flask
      - [X] function create_app(), Create a Flask application using the app factory pattern
    - [X] Blueprints and Jinja2 Templates
      - [X] Blueprints: components of the web app
      - [X] App Folder/Blueprints/Page/views.py
    - [X] Develop Patterns
      - [X] Django uses MTV (model-template-view)
	- [X] database models
	- [X] html templates
	- [X] router views, http render
      - [X] Rails uses MVC (model-view-controller)
      - [X] Flasks I'm doing will stick with MTVish pattern
    - [X] Deciding on a consistent and crisp look for the app
      - [X] start from zero: not really
      - [X] Bootstrap+Awesome Fonts
      - [X] App Folder/static folder
	- [X] fonts: asesome fonts
	- [X] images: logos +
	- [X] scripts: JS
	- [X] styles: css
	- [X] recommended to separate vendor folders from our own folders
    - [X] Jinja 2
      - [X] a designer friendly templating language for python
      - [X] Top features:
	- [X] template inheritance
	- [X] HTML escaping, web security
	- [X] Speed and efficiency
	- [X] Flexible and extensibility
      - [X] Cudos for me:
	- [X] Add programming constructs to HTML templates
	- [X] Transfer info from backend Flask server to HTML templates for viewers
	  - [X] Imagine listing users in an admin dashboard
	- [X] Separate data from the presentation
    - [ ] Testing: Looks like should be useful once we have a site built
      - [ ] Review section 08 again
      - [ ] Finish Challenge
    - [ ] CLI Script: to automate the process
      - [ ] Review section 09 again
      - [ ] Finish Challenge

** Date:<2017-03-26 Sun>
*** Bokeh
    - [ ] import libraries
      - [ ] from bokeh.plotting import figure
      - [ ] from bokeh.io import output_file, show
    - [ ] four lines of coding
      - [ ] output_file("filename.html")
      - [ ] f=figure()
      - [ ] f.line(x,y) #other proper charting
      - [ ] show(f)
      - [ ] f.logo=None # Remove bokeh logo
** Date: <2017-03-27 Mon>
*** Flask
    - [ ]
*** MySQL
    - [ ] Don't forget the ; at the end of each query
    - [ ] Connet to Mysql
      - [ ] mysql --user=root -p, then enter password
    - [ ] show all databases
      - [ ] SHOW DATABASES;
    - [ ] create, delete databases, select database
      - [ ] CREATE DATABASE database_name;
      - [ ] DROP DATABASE database_name;
      - [ ] USE database_name;
    - [ ] create delete tables
      - [ ] after selecting database
      - [ ] CREATE TABLE table_name;
      - [ ] DROP TABLE table_name;
*** Bokeh
    - [ ]
*** Pandas
    - [ ]
** Date: <2017-03-28 Tue>
*** Bokeh
    - [X] start services
      - [X] service nginx restart
      - [X] service supervisor restart
      - [X] supervisorctl restart flask
      - [X] supervisorctl restart bokeh_serve
*** Linux
    - [ ] Remove postgresql
      - [ ] sudo apt-get --purge remove postgresql postgresql-doc postgresql-common
** Date: <2017-03-29 Wed>
*** Deployement
**** Setup
    - [ ] DigitalOcean
    - [ ] Change linux logins
    - [ ] install softwares
      - [ ] apt-get install python-virtualenv nginx gunicorn supervisor python-pip
      - [ ] mkdir /opt/envs
      - [ ] virtualenv /opt/envs/virtual
      - [ ] . /opt/envs/virtual/bin/activate
      - [ ] pip install bokeh
      - [ ] pip install flask
      - [ ] pip install gunicorn
      - [ ] mkdir /var/log/nginx/flask
      - [ ] mkdir /opt/webapps
      - [ ] mkdir /opt/webapps/bokehflask
    - [ ] configuration files
      - [ ] app files
      - [ ] default --> 
      - [ ] flask.conf -->
      - [ ] bokeh_serve.conf -->
    - [ ] start services
      - [ ] service nginx restart
      - [ ] service supervisor restart
      - [ ] supervisorctl restart flask
      - [ ] supervisorctl restart bokeh_serve
**** Bokeh Server
     - [ ] python -m bokeh serve **.py
     - [ ] bokeh serve **.py
     - [ ] bokeh serve --allow-websocket-origin=localhost:5000 xxx.py
**** Debug
     - [ ] /var/log/supervisor
**** Jupyter to Atom
     - [ ] select mutiple cells: esc, shift J
     - [ ] merge: shift m

** Date:<2017-03-30 Thu>
*** MySQL
    - [ ] mysql --user=root -p
    - [ ] show databases;
    - [ ] use database;
    - [ ] show tables;
** Date:<2017-03-31 Fri>
*** AVA Bi-Weekly Updates
    - [X] Website: Show 138.197.111.0
      - [X] register
	- [X] live register demo
	- [X] Hash encryption
      - [X] sign in
      - [X] server configuration <2017-04-04 Tue>
	- [X] Show 104.236.13.102
	- [X] Show bitcoin trading example
	- [X] Address the issue with server error
    - [X] Functionalities (dropdown boxes, multiple selections, export to excel button)
      - [X] Database load and manipulation: AppDemo_Datamanipulation
	- [X] Dabase Selection and Load,
	- [X] Dropdown box selection,
	- [X] mutiple selections,
	- [X] export to excel file
      - [X] Idea Generation (Bruce's wish)
	- [X] accordion selection widgets (lumped together)
      - [X] Visualiztion
	- [X] Python3 vs. Python2 libraries clash: Prioritizing fixing now
	- [X] Fix by <2017-04-02 Sun>
    - [X] Next Step
      - [X] Visualization libraries
      - [X] Server configuration
** Date:<2017-04-01 Sat>
*** Website Structure:
** Date: <2017-04-05 Wed>
*** Bokeh
    - [ ] Widgets
      - [ ] Udemy
      - [ ] Loading Database Page
    - [ ] Bokeh Server
    - [ ] Embed Bokeh Apps in Website
    - [ ] Deploy
** Date: <2017-04-06 Thu>
*** Deployment
    - [ ] Virtual environment
      - [ ] . /opt/envs/virtual/bin/activate
    - [ ] Create log files
      - [ ] mkdir /var/log/nginx/flask
    - [ ] Create webapp folders
      - [ ] mkdir /opt/webapps
      - [ ] mkdir /opt/webapps/bokehflask

* 2017-May-Log
** May 5 in NYC <2017-05-03 Wed>                                        :day:
*** Emacs Configuration                                         :emacsconfig:
- Uninstall emacs
  sudo apt-get remove --auto-remove emacs24 emacs24-lucid emacs24-nox
- Install emacs
  sudo apt-get install emacs
- customize theme
  customize-group faces: change fonts, forefront etc.
  customize-group packages: add melpa as additional package
  M-x list-packages, search for monokai and install monokai
- install neo-tree
  https://www.emacswiki.org/emacs/NeoTree
- install python IDE
  https://github.com/wernerandrew/jedi-starter
- configure Org for code test
  http://vislab-ccom.unh.edu/~schwehr/rt/9-bash-scripting.html
*** Operation Research Chapter 2                          :OperationResearch:
- Phases of OR Study
  1. Define the problem
  2. Formulate a math model to present the problem
  3. Develop a computer-based procedure to derive solutions
  4. Test the model and refine it as needed
  5. Prepare for the application of the model
  6. Implement
*** Python and Spark                                           :python:spark:
- Big Data
  1. use a SQL database to move storage onto hard drive instead of RAM
  2. use a distributed system to distribute the data to multiple machines/computers
- Local versus Distributed
** May 6 in NYC <2017-05-06 Sat>                                        :day:
*** Org mode
- Import library, finally was able to use right python version, check the .emacs file
#+BEGIN_SRC ipython :session
import numpy as np
np.random.randint(1, 100)
import sys
sys.version
#+END_SRC

#+RESULTS:
: 59

1. Python
#+begin_src python :results file
import matplotlib, numpy
matplotlib.use('Agg')
import matplotlib.pyplot as plt
fig=plt.figure(figsize=(4,2))
x=numpy.linspace(-15,15)
plt.plot(numpy.sin(x)/x)
fig.tight_layout()
plt.savefig('/home/isaac/Pictures/python-matplot-fig.png')
return '/home/isaac/Pictures/python-matplot-fig.png' # return filename to org-mode
#+end_src

#+RESULTS:
[[file:/home/isaac/Pictures/python-matplot-fig.png]]

2. R

- R code
#+begin_src R :file 3.png :results output graphics
library(lattice)
xyplot(1:10 ~ 1:10)
#+end_src

#+RESULTS:
[[file:3.png]]

3. Octave
#+BEGIN_SRC octave
  figure( 1, "visible", "off" );
  sombrero;
  print -dpng chart.png;
  ans = "chart.png";
#+END_SRC

#+RESULTS:
: chart.png

4. Shell
#+BEGIN_SRC shell :results output
ls -l
#+END_SRC

*** Python Bokeh                                               :python:bokeh:
- Section 1 Basics
#+begin_src python :results file
# Importing bokeh library
from bokeh.plotting import figure
from bokeh.io import output_file, show

#prepare some dummy data
x = list(range(6))
y = list(range(11,16))

#prepare the output file
output_file("line.html")

#create a figure object
f = figure()

#create line plot
f.line(x, y)

#create circle plot
#f.circle(x,y)
f.triangle(x,y)

#write the plot in the figure object
show(f)
#+end_src

#+RESULTS:
[[file:None]]

#+start_src python :results file

#+end_src
*** RT2011                                                         :research:
- Link
http://vislab-ccom.unh.edu/~schwehr/rt/
** May 7 in NYC <2017-05-07 Sun>                                        :day:
*** Emacs + Org-mode + Python in reproducible research     :emacs:org:python:
- link: https://www.youtube.com/watch?v=1-dUkyn_fZA&t=334s

#+BEGIN_SRC python
import sys
return(sys.version)
return(sys.prefix)
#+END_SRC

#+RESULTS:
: 3.6.0 |Anaconda 4.3.1 (32-bit)| (default, Dec 23 2016, 12:22:10) 
: [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]

- inline image
#+STARTUP: inlineimages
[[/home/isaac/OrgEmacs/images/org-mode-unicorn-logo.png]]


#+BEGIN_SRC shell
pwd
#+END_SRC

#+RESULTS:
: /home/isaac/OrgEmacs
- import a table from a data file
run: M-x org-table-import and will input the file to insert
C-c - to insert a line
|  x |  y |  z |
|----+----+----|
|  1 |  2 |  3 |
|  4 |  5 |  6 |
|  7 |  8 |  9 |
| 10 | 11 | 12 |

#+BEGIN_SRC emacs-lisp 
(+ 7 8)
#+End_SRC

#+RESULTS:
: 15
- auto completion
line: http://orgmode.org/manual/Easy-Templates.html

#+BEGIN_SRC python
import numpy as np
return(np.random.randn(5))
#+END_SRC

#+RESULTS:
| 0.56748746 | 0.40787367 | -0.84858254 | 1.47541833 | -0.45440653 |

<<<<<<< HEAD
*** Udacity 3 Recurrent Neural Networks                         :udacity:RNN:

**** Intro to RNN

***** 

=======
*** Udacity                                            :udacity:deeplearning:
- [ ] 
- [ ]  
  - [ ]
*** Grokking Deep Learning                                :book:deeplearning:
**** Chapter3 Forward Propagation
***** Simple NN to make prediction, with one input
#+BEGIN_SRC python
weight = 0.1
def neural_network(input, weight):
    prediction = input * weight
    return prediction

number_of_toes = [8.5, 9.5, 10, 9]
input = number_of_toes[0]
pred = neural_network(input, weight)
return(pred)
#+END_SRC

#+RESULTS:
: 0.8500000000000001
***** Multiple NN to make predidction
#+BEGIN_SRC python
weights = [0.1, 0.2, 0]
toes = [8.5, 9.5, 9.9, 9]
wlrec = [0.65, 0.8, 0.8, 0.9]
nfans = [1.2, 1.3, 0.5, 1]

def neural_networks(input, weights):
    pred = w_sum(input, weights)
    return pred

def w_sum(input, weights):
    assert(len(input)==len(weights))
    output = 0
    for i,j in zip(input,weights):
        output += (i * j)
    return output

input = [toes[0], wlrec[0], nfans[0]]
pred = neural_networks(input, weights)

return pred
#+END_SRC

#+RESULTS:
: 0.9800000000000001

** May 8 in NYC <2017-05-08 Mon>                                        :day:
*** DONE Tasks                                                         :todo:
**** DONE Optimization<2017-05-12 Fri>
     - [X] review the fundamentals
     - [X] review WB example models
     - [X] Build analytics applets
       + [X] Purchasing: light steel opt
       + [X] Pricing
       + [X] Inventory
       + [X] Logistics
       + [X] Portfolio
**** DONE AVA webapp<2017-05-14 Sun>
     - [ ] data refresh
     - [ ] Additional features
       - [ ] Data cleansing
       - [ ] stat/analysis tables
       - [ ] add EPS
       - [ ] EVA sensitivity analysis
     - [ ] Database + app merge
     - [ ] Deployment
*** Optimization Notes                                         :optimization:
**** Python linear programming
 Use scipy.optimize linear programming for optimization issues
 #+BEGIN_SRC python
 c = [-1, 4]
 A = [[-3, 1], [1,2]]
 b = [6, 4]
 x0_bound = (None, None)
 x1_bound = (-3, None)

 from scipy.optimize import linprog
 res = linprog(c, A_ub = A, b_ub = b, bounds=(x0_bound, x1_bound), options={'disp':True})
 return res
 #+END_SRC

 #+RESULTS:
 : fun: -22.0
 :  message: 'Optimization terminated successfully.'
 :      nit: 1
 :    slack: array([ 39.,   0.])
 :   status: 0
 :  success: True
 :        x: array([ 10.,  -3.])
**** Crash Course in Linear Programming
***** Math: Need 3 ingredients
****** Decision Variables
****** Objectives
****** Constraints
***** Python: Need 2 components
****** Solver
******* GLPK
******* GUROBI
****** Modeling Framework
******* Scipy
******* PyOMO
******* PuLP
#+BEGIN_SRC python 
from pulp import LpProblem, LpMinimize, LpVariable, LpInteger
prob = LpProblem("Diet", LpMinimize)

#Decision variables
x1 = LpVariable("Steak", 0, None, LpInteger)
x2 = LpVariable("PB", 0, None, LpInteger)

#Objectives
prob += 2 * x1 + 3 * x2 #"Total Cost"

#Constraints
prob += x1 + 2 * x2 >= 4 # "Min protein intake"

return prob.solve()
#+end_SRC

#+RESULTS:
: 1

*** Grokking Deep Learning                                :book:deeplearning:
**** Chapter3 Forward Propagation
***** Multiple NN numpy code
  #+BEGIN_SRC python
  import numpy as np
  weights = np.array([0.1, 0.2, 0])

  def neural_network(input, weights):
      pred = input.dot(weights)
      return pred

  toes = np.array([8.5, 9.5, 9.9, 9])
  wlrec = np.array([0.65, 0.8, 0.8, 0.9])
  nfans = np.array([1.2, 1.3, 0.5, 1.0])

  input = np.array([toes[0], wlrec[0], nfans[0]])
  pred = neural_network(input, weights)
  return(pred)
  #+END_SRC

  #+RESULTS:
  : 0.98
***** Multiple Outputs
NN can also make multiple predictions using only a single input
#+BEGIN_SRC python
weights = [0.3, 0.2, 0.9]

def neural_network(input, weights):
    pred = ele_mul(input, weights)
    return pred

def ele_mul(number,vector):
    output=[0,0,0]
    assert(len(output)==len(vector))
    for i in range(len(vector)):
        output[i] = number * vector[i]
    return output

wlrec = [0.65, 0.8, 0.8, 0.9]
input = wlrec[0]
pred = neural_network(input, weights)
return pred
#+END_SRC

#+RESULTS:
| 0.195 | 0.13 | 0.5850000000000001 |

***** Prediction with Multiple Inputs & Outputs
Build a network with multiple inputs or outputs
#+BEGIN_SRC python
import numpy as np
weights = np.array([[0.1, 0.1, -0.3], [0.1, 0.2, 0],[0, 1.3, 0.1]])
def neural_network(input, weights):
    pred = vect_mat_mul(input, weights)
    return pred

def vect_mat_mul(a, b):
    assert(len(a)==len(b))
    output = np.zeros(len(a))
    for i in range(len(a)):
        output[i] = np.dot(a,b[i])
    return output

toes = np.array([8.5, 9.5, 9.9, 9.0])
wlrec = np.array([0.65, 0.8, 0.8, 0.9])
nfans = np.array([1.2, 1.3, 0.5, 1])

input = np.array([toes[0], wlrec[0], nfans[0]])
pred = neural_network(input, weights)

return pred
#+END_SRC

#+RESULTS:
| 0.555 | 0.98 | 0.965 |
*** AVA Webapp
** May 9 in NYC <2017-05-09 Tue>                                        :day:
*** TODO Tasks
**** Build a dummpy steel optimization tool
**** Pelican
**** AVA 
***** Data update/clean
***** Code JS callback
*** 
** May 10 in NYC <2017-05-10 Wed>                                       :day:
*** Bokeh                                                      :python:bokeh:
**** Getting Started
#+BEGIN_SRC python :results output
import numpy as np
import pandas as pd
data = pd.read_csv("/home/isaac/Dropbox/OPT/factory/factory.csv")
#+END_SRC

#+RESULTS:

**** Dive into Bokeh
**** Customize Bokeh Graph
**** Advanced Plotting
**** Bokeh Server: Interactive Plots & Widgets
**** Bokeh Server: Streaming Real Time Data
**** Embedding Bokeh Apps in Websites
**** Deployment
** May 11 in NYC <2017-05-11 Thu>                                       :day:
*** DONE Tasks
**** AVA update
***** Finish update slide
**** OPT model
***** 
**** AVA webapp                                                        :todo:
*** Fix usb drive                                                       :fix:
1. diskpart with admin
2. list disk
3. select disk number
4. clean
5. create partition primary
6. exit
*** Manjaro Installation                                              :linux:
**** Etcher to burn usb disk: https://etcher.io/
**** 
*** Docker                                                           :docker:
**** Installation                                       :docker:installation:
 - link: http://apt.dockerproject.org/repo/pool/main/d/docker-engine/
 - get 1.8.3 trusty
 - install docker dependencies: sudo apt-get install libapparmor1 aufs-tools ca-certificates
 - install docker: sudo dpkg -i docker-engine_1.8.3-0-trusty_amd64.deb
 - add user to the docker group so that can run Docker without root: sudo usermod -aG docker $(whoami)
 - reboot
 - install docker compose
   - curl -L https://github.com/docker/compose/releases/download/1.4.2/docker-compose-Linux-x86_64 > /tmp/docker-compose
   - chmod +x /tmp/docker-compose
   - sudo mv /tmp/docker-compose /usr/local/bin
   - docker-compose --version

**** Uninstall Steps
 - sudo apt-get purge -y docker-engine
 - sudo apt-get autoremove -y --purge docker-engine
 - sudo apt-get autoclean
 - sudo rm -rf /var/lib/docker
 - sudo rm /etc/apparmor.d/docker
 - sudo groupdel docker

**** Delete Docker
 - Delete all docker containers: docker rm $(docker ps -a -q)
 - Delete all docker images: docker rmi $(docker images -q)

**** Docker Hello World
 - docker image: class
   - docker container: instance
 - busybox: extremely small linux
 - docker run
 - docker --help
 - docker run -it --rm busybox:latest
 - C-d to exit docker
 - docker containers are immutable
 - docker delete container: docker rm
 - docker delete images: docker rmi

**** Docker Registry
 - registered on docker hub

**** Setup a project
 - project scafolding
 - Project folder --> website folder
 - create some empty files: touch requirements.txt .gitignore Dockerfile docker-compose.yml .dockerignore
 -

**** Setup Dockerfile

**** Building the app
** May 12 in NYC <2017-05-12 Fri>                                       :day:
*** TODO TASKS                                                         :TODO:
1. BOKEH WIDGETS & INTERACTIVITY
2. AVA update
3. Javascript
4. OPT
*** Jupyter Notbook/Ipython Dashboard
- https://www.youtube.com/watch?v=V3VxQGevHCU
- Will check out: https://www.youtube.com/watch?v=LOWBEYDkn90
*** Emacs                                                             :emacs:
**** Emacs config
- Will not use .emacs file, instead use .init.el file and place it in .emacs.d
- https://emacs.stackexchange.com/questions/12881/how-do-i-set-a-different-location-for-the-dot-emacs-emacs-file-on-windows-7
- https://www.emacswiki.org/emacs/DotEmacsDotD
**** return with auto indent
- C-j
- https://www.emacswiki.org/emacs/AutoIndentation
**** replace
- M-%, use ! to replace all
*** VirtualBox                                                   :virtualbox:
**** How to add spaces
- http://derekmolloy.ie/resize-a-virtualbox-disk/#prettyPhoto
**** After adding spaces, the boot will be slow, use below
- https://superuser.com/questions/1084147/virtualbox-very-slow-boot-time
*** Bokeh Notes                                                :python:bokeh:
**** Column Data Source
1. CDS is created to easily use pandas dataframe
#+BEGIN_SRC python :results output
from bokeh.sampledata.iris import flowers
print(flowers[:5])
#+END_SRC

#+RESULTS:
:    sepal_length  sepal_width  petal_length  petal_width species
: 0           5.1          3.5           1.4          0.2  setosa
: 1           4.9          3.0           1.4          0.2  setosa
: 2           4.7          3.2           1.3          0.2  setosa
: 3           4.6          3.1           1.5          0.2  setosa
: 4           5.0          3.6           1.4          0.2  setosa

2. 
**** Hover
**** Bokeh Widgets and Server
- Widgets interactivity has to be executed in the bokeh server
- bokeh serve appname --port 5007 (or any other port if port is taken)
** May 14 in NYC <2017-05-14 Sun>                                       :day:
*** Flask Tutorial
- [[http://blog.thedataincubator.com/2015/09/painlessly-deploying-data-apps-with-bokeh-flask-and-heroku/][Deploy Data App with Bokeh, Flask and Heroku]]
** May 15 in NYC <2017-05-15 Mon>                                       :day:
*** Org-Mode
**** Outliner
**** Mark up
***** *Bold*, /italic/, /test/, _test_, =verbatim=
**** Bulleted list
- list1
- list2
**** links
- External links to website
  - C-c C-l: enter links and description
  - C-c C-o: open links
[[http://www.google.com][Google]]

- Internal links to files

**** Tables
|  A |  B |
|----+----|
| 12 | 79 |
| 34 | 45 |

**** Export to other format
#+Title: A Gentle Intro to Org-Mode
#+Options: author:nil date:nil email:nil creator:nil timestamp:nil

**** Source code
- C-c ' to editor
- C-c ' to quit editor
#+BEGIN_SRC python :results output :exports both
  import numpy as np
  print(np.random.random(10))
#+END_SRC

#+RESULTS:
: [ 0.08153801  0.08220896  0.28221283  0.45509195  0.83788436  0.13067804
:   0.52464921  0.28018272  0.107593    0.17557978]

**** LaTex integration
- Characters: \alpha \rightarrow \beta
- $O(n \log n)$
\begin{align*}
3 * 2 + &= 6 + 1 \\
&= 7
\end{align*}

**** Literate Programming
- set up all config in an org model file
- babel it with emacs-lisp
- only one line of code in the .init.el file
  - (org-babel-load-file "~/.emacs.d/configuration.org")
**** Todo Stuffs
***** TODO explain todo lists
      DEADLINE: <2017-05-17 Wed>
***** TODO cycle through states
***** DONE (S-left)<2017-05-14 Sun>
**** Export
***** [[http://orgmode.org/manual/Export-settings.html#Export-settings][Official Export Settings]]
***** [[https://github.com/marsmining/ox-twbs][Export org-mode docs as HTML compatible with Bootstrap]]
***** [[https://jgkamat.github.io/blog/website1.html][Create Blog from Org]]
*** AVA
**** Codes
**** User Management
**** Data
** May 16 in NYC <2017-05-16 Tue>                                       :day:
*** AVA Webapp Core Apps
**** Select Database
1. Select which folder on the server to pull data
2. All the following data will be encapsuled into this one
**** Select Table/Metric
1. Select which metric to pull
2. Download CSV
3. Further selections include
|---------+----------------------------|
| Region  | e.g. North America, Europe |
|---------+----------------------------|
| Country | e.g. USA, Germany          |
|---------+----------------------------|
| Sector  | e.g. Auto OEM              |
|---------+----------------------------|
**** Charts
1. Select metrics (Multiple Selection)
2. Enter Company Names
3. Populate Charts
**** Tables
*** Bokeh
**** Widget Document
1. [[http://bokeh.pydata.org/en/latest/docs/user_guide/interaction/widgets.html#multiselect][Bokeh Widget]]
2. 
** May 17 in NYC <2017-05-17 Wed>                                       :day:
*** TODO AVA Core Apps
*** TODO Data Update
*** Emacs
**** Undo: C-_
**** Redo changes: C-g C-_
**** Repeat: C-u number action
***** print $ for 20 times
***** $$$$$$$$$$$$$$$$$$$$
** May 19 in NYC <2017-05-19 Fri>                                       :day:
*** AVA
*** Linux
**** count number of files in a dir
***** ls -F |grep -v / | wc -l
**** Given two directory trees, find out which files differ:
***** diff --brief -r dir1/ dir2/
***** If nothing prints out, means two dirs have same files
***** The differences will be printed out
**** readlink -f filename
***** Getting the full path 
** May 20 in NYC <2017-05-20 Sat>                                       :day:
*** TODO AVA webapp
**** Optimize code
***** Learning from examples
*** TODO Optimization
*** TODO Deep Learning Nano Degree
*** Testing op-python
#+BEGIN_SRC ipython :session :file /home/isaac/Documents/image.svg :exports both
  %matplotlib inline
  %config InlineBackend.figure_format = 'svg'
  import matplotlib.pyplot as plt
  import numpy as np

  def foo(x):
      return x + 9

  [foo(x) + 7 for x in range(7)]

  plt.hist(np.random.randn(1000), bins=100)
#+END_SRC

#+RESULTS:
[[file:/home/isaac/Documents/image.svg]]
*** Udacity Matrix and Numpy Refresher
****** Types of Data
******* Scalar: zero dimensions
******* Vectors: 1 dimension: row or column
******* Matrix: [row,column]
******* Tensors: n dimensions, hard to visualize if n > 3
****** Numpy
******* Python is slow, however it's possible to import libraries which run faster written in C
#+BEGIN_SRC ipython :session
  import numpy as np
  s = np.array([[1,2,3], [4,5,6], [7,8,9]])
  [x for x in s]
  t = np.array([[[[1],[2]],[[3],[4]],[[5],[6]]],[[[7],[8]],\
      [[9],[10]],[[11],[12]]],[[[13],[14]],[[15],[16]],[[17],[17]]]])
  [x for x in t]
  t.shape
  t.reshape(3,2,1,3)
#+END_SRC

#+RESULTS:
#+begin_example
array([[[[ 1,  2,  3]],

        [[ 4,  5,  6]]],


       [[[ 7,  8,  9]],

        [[10, 11, 12]]],


       [[[13, 14, 15]],

        [[16, 17, 17]]]])
#+end_example

*** Bokeh Strata NYC 2016
****** Load bokeh
****** Basic plots
#+BEGIN_SRC ipython :session
  from bokeh.io import output_file, show
  from bokeh.plotting import figure
  from bokeh.layouts import column, row
  import pandas as pd

  path = "/home/isaac/Dropbox/Bokeh/bokeh-notebooks/tutorial/assets/gapminder.csv"
  df = pd.read_csv(path, thousands=",", index_col="Year")
  df.loc[2010].head()

  output_file("/home/isaac/Dropbox/OrgEmacs/bokehout/example.html")

  p1 = figure(width=600)
  p1.circle(x=df.loc[2010]["income"], y=df.loc[2010]["life"], size=12, line_color="navy", fill_color="orange", alpha = 0.5)

  p2 = figure(width=600)
  p2.circle_x(x=df.loc[2010]["income"], y=df.loc[2010]["life"], size=10, fill_color="firebrick", line_color="#66BAB7",alpha = 0.5)

  lay_out = row(p1, p2)

  show(lay_out)
#+END_SRC

#+RESULTS:
****** Line Plots
#+BEGIN_SRC ipython :session
  from bokeh.io import output_file, show
  from bokeh.plotting import figure
  from bokeh.layouts import column, row
  import pandas as pd

  path = "/home/isaac/Dropbox/Bokeh/bokeh-notebooks/tutorial/assets/gapminder.csv"
  df = pd.read_csv(path, thousands=",", index_col="Year")
  df.loc[2010].head()

  output_file("/home/isaac/Dropbox/OrgEmacs/bokehout/example.html")

  p1 = figure(width=600)
  p1.line(x=df.index, y=df[df["Country"]=="United States"]["income"], line_color="firebrick")
  p1.line(x=df.index, y=df[df["Country"]=="China"]["income"], line_color="red")
  p1.line(x=df.index, y=df[df["Country"]=="Germany"]["income"], line_color="black")

  show(p1)

#+END_SRC

#+RESULTS:
****** Use vbar to create histogram
# Change to python, which is faster than ipython
#+BEGIN_SRC python :results output
  from bokeh.io import output_file, show
  from bokeh.plotting import figure
  from bokeh.layouts import column, row
  from bokeh.palettes import Spectral5
  import pandas as pd

  output_file("/home/isaac/Dropbox/OrgEmacs/bokehout/example.html")

  p1 = figure(width=600)
  p1.vbar(bottom = 0, x=[1,2,3,4,5], top=[7,5,6,9,8],color=Spectral5, width=0.5)
  p1.line(x=[1,2,3,4,5], y = [x/2 for x in [7,5,6,9,8]], line_width=5)
  p1.circle(x=[1,2,3,4,5], y = [x/2 for x in [7,5,6,9,8]], color="firebrick", size=15)
  show(p1)
  print(Spectral5)
#+END_SRC

#+RESULTS:
: ['#2b83ba', '#abdda4', '#ffffbf', '#fdae61', '#d7191c']
****** Formatting the gapminder
#+BEGIN_SRC python :results output
  from bokeh.io import output_file, show
  from bokeh.plotting import figure
  from bokeh.layouts import column, row
  import pandas as pd

  path = "/home/isaac/Dropbox/Bokeh/bokeh-notebooks/tutorial/assets/gapminder.csv"
  df = pd.read_csv(path, thousands=",", index_col="Year")
  df.loc[2010].head()

  output_file("/home/isaac/Dropbox/OrgEmacs/bokehout/example.html")

  p = figure(width=600, x_axis_type="log", x_range=(1000,100000), \
	     y_range =(0,100),title="2010",x_axis_label="Income", y_axis_label="Life Expectancy")
  p.circle(x=df.loc[2010]["income"], y=df.loc[2010]["life"], size=12, line_color="navy", fill_color="orange", alpha = 0.5)

  show(p)

#+END_SRC

#+RESULTS:
****** Column Data Source
#+BEGIN_SRC python :results output
  from bokeh.io import output_file, show
  from bokeh.plotting import figure
  from bokeh.layouts import column, row
  from bokeh.models import ColumnDataSource
  import pandas as pd

  path = "/home/isaac/Dropbox/Bokeh/bokeh-notebooks/tutorial/assets/gapminder.csv"
  df = pd.read_csv(path, thousands=",", index_col="Year")
  df.loc[2010].head()

  df_cds = ColumnDataSource(df.loc[2010])
  output_file("/home/isaac/Dropbox/OrgEmacs/bokehout/example.html")

  p = figure(width=600, x_axis_type="log", x_range=(1000,100000), \
	     y_range =(0,100),title="2010",x_axis_label="Income", y_axis_label="Life Expectancy")
  p.circle(x="income", y="life", source=df_cds,size=12, line_color="navy", fill_color="orange", alpha = 0.5)

  show(p)
#+END_SRC

#+RESULTS:
******* *All Columns in the CDS MUST be of the Same Length*
******* 
#+BEGIN_SRC python
    from bokeh.io import output_file, show
    from bokeh.plotting import figure
    from bokeh.layouts import column, row
    from bokeh.palettes import Spectral5
    import pandas as pd
    import numpy as np

    output_file("/home/isaac/Dropbox/OrgEmacs/bokehout/example.html")
    x = np.array(range(1,100))
    y = np.random.random(100)
    z = np.random.randn(100)
    source_1 = {"x":x, "y":y}
    p1 = figure(width=600)
    p2 = figure(width=600)
    source_2 = {"x":x, "z":z}


    p1.circle(x=x, y=y, source = source_1, color=Spectral5, size=10)
    p2.circle(x=x, y=z, source=source_2, color =Spectral5, size=10)

    lay_out = row(p1,p2)
    show(lay_out)
#+END_SRC

#+RESULTS:
: None

#+BEGIN_SRC python
  from bokeh.io import output_file, show
  from bokeh.plotting import figure
  from bokeh.layouts import column
  from bokeh.palettes import Spectral5
  import pandas as pd
  import numpy as np

  from bokeh.sampledata.iris import flowers as df
  from bokeh.models import ColumnDataSource

  source = ColumnDataSource(df)

  plot = figure(width=800)
  plot.circle(x = "petal_length", y = "petal_width", source=source, color = "firebrick", size=15, alpha=0.85)

  output_file("/home/isaac/Dropbox/OrgEmacs/bokehout/example.html")

  show(plot)
#+END_SRC

#+RESULTS:
: None

#+BEGIN_SRC python
  from bokeh.io import output_file, show
  from bokeh.plotting import figure
  from bokeh.layouts import column, row
  import pandas as pd
  from bokeh.palettes import Spectral6
  from bokeh.models import ColumnDataSource, HoverTool

  path = "/home/isaac/Dropbox/Bokeh/bokeh-notebooks/tutorial/assets/gapminder.csv"
  df = pd.read_csv(path, thousands=",", index_col="Year")
  df.loc[2010].head()
  regions = df["region"].unique().tolist()

  def get_color(r):
      return Spectral6[regions.index(r["region"])]

  def make_plot():
      p = figure(width=900, x_axis_type="log", x_range=(1000, 100000))
      return p


  df["region_color"] = df.apply(get_color, axis=1)
  source = ColumnDataSource(
      {"income": df["income"], "life":df["life"], "population":df["population"], "country":df["Country"]}
  )

  #  source = ColumnDataSource(df.loc[2010])

  hover = HoverTool(tooltips = "@country")

  p1 = make_plot()
  p1.circle(x="income", y="life", size=12, line_color="navy", fill_color="region_color", source=source)
  p1.add_tools(hover)

  p2 = figure(width=900, x_range=(0,200000000))
  p2.circle(x="population", y="life", size=12, fill_color="region_color", source=source)
  p2.add_tools(hover)

  lay_out = column(p1, p2)

  output_file("/home/isaac/Dropbox/OrgEmacs/bokehout/example.html")
  show(lay_out)

#+END_SRC

#+RESULTS:
****** Interaction
******* gridplot
#+BEGIN_SRC python
  from bokeh.io import output_file, show
  from bokeh.plotting import figure
  from bokeh.layouts import column, row, gridplot
  from bokeh.palettes import Spectral5
  import pandas as pd
  import numpy as np

  output_file("/home/isaac/Dropbox/OrgEmacs/bokehout/example.html")
  x = np.array(range(1,100))
  y = np.random.random(100)
  z = np.random.randn(100)
  source_1 = {"x":x, "y":y}
  p1 = figure(width=500)
  p2 = figure(width=500)
  source_2 = {"x":x, "z":z}

  p3 = figure(width=1000)
  source_3 = {"x":y, "z":z}


  p1.circle(x=x, y=y, source = source_1, color=Spectral5, size=10)
  p2.circle(x=x, y=z, source=source_2, color =Spectral5, size=10)
  p3.circle(x=x, y=z, source=source_3, color=Spectral5, size=10)

  lay_out = gridplot([[p1,p2],[p3]], toolbar_location=False)
  show(lay_out)

#+END_SRC

#+RESULTS:
: None
******* Shared ranges
#+BEGIN_SRC python
  from bokeh.io import output_file, show
  from bokeh.plotting import figure
  from bokeh.models import ColumnDataSource
  from bokeh.layouts import gridplot
  import numpy as np

  x = np.random.randn(100)
  y = np.random.random(100)
  z = x + y

  f1 = figure(width = 400)
  f1.circle(x, y, color = "red")

  f2 = figure(width = 400, x_range=f1.x_range, y_range=f1.y_range)
  f2.circle(x, z, color = "black")

  lay_out = gridplot([[f1,f2]])
  output_file("/home/isaac/Dropbox/OrgEmacs/bokehout/example.html")
  show(lay_out)
#+END_SRC

#+RESULTS:
: None
******* Shared sources, different views
#+BEGIN_SRC python
  from bokeh.io import output_file, show
  from bokeh.sampledata.iris import flowers as df
  from bokeh.models import ColumnDataSource
  from bokeh.plotting import figure
  from bokeh.layouts import row, column, gridplot

  source = ColumnDataSource(df)
  TOOLS = "box_select, lasso_select"

  p1 = figure(width = 500, tools=TOOLS)
  p1.circle("sepal_width", "sepal_length", source=source)
  p2 = figure(width = 500, tools=TOOLS, x_range = p1.x_range, y_range=p1.y_range)
  p2.circle("sepal_width", "petal_length", source=source)
  output_file("/home/isaac/Dropbox/OrgEmacs/bokehout/example.html")

  lay_out = gridplot([[p1, p2]])
  show(lay_out)
#+END_SRC

#+RESULTS:
: None
******* Link to Notebook widget (might be very useful when Notebook -> App gets better to use)
******* Widgets
#+BEGIN_SRC python
  from bokeh.io import output_file, show
  from bokeh.sampledata.iris import flowers as df
  from bokeh.models import ColumnDataSource, Slider, Select
  from bokeh.plotting import figure
  from bokeh.layouts import row, column, gridplot, widgetbox

  source = ColumnDataSource(df)

  slider = Slider(start=0, end=10, step=1)
  select = Select(options=["Yes","No"], value="Yes")
  output_file("/home/isaac/Dropbox/OrgEmacs/bokehout/slider.html")
  show(widgetbox(slider, select))

#+END_SRC

#+RESULTS:
: None
******* JS Callback: would be useful for stand alone html, need to study JS first
******** 
****** Styling Visual Attributes
******* Color and Properties
#+BEGIN_SRC python
  from bokeh.io import output_file, show
  from bokeh.plotting import figure
  p = figure(width=400, height=400, tools="tap, reset", title="select a circle")
  renderer = p.circle([1,2,3,4,5], [2,5,8,2,7], size = 25,
		      selection_color="firebrick",
		      nonselection_fill_alpha=0.2,
		      nonselection_fill_color="grey",
		      nonselection_line_color = "firebrick",
		      nonselection_line_alpha=1.0)
  output_file("/home/isaac/Dropbox/OrgEmacs/bokehout/select_highlight.html")
  show(p)

#+END_SRC

#+RESULTS:
: None
****** Data Transformation
#+BEGIN_SRC ipython :session
  from bokeh.sampledata.autompg import autompg as df
  from bokeh.models import ColumnDataSource
  from bokeh.io import output_file, show
  from bokeh.plotting import figure
  from bokeh.layouts import column, row, gridplot
  from bokeh.palettes import Spectral5
  import pandas as pd
  import numpy as np

  output_file("/home/isaac/Dropbox/OrgEmacs/bokehout/example.html")
  source = ColumnDataSource(df)

  p = figure()
  p.circle("yr", "mpg", source=source)

  show(p)
#+END_SRC

#+RESULTS:
****** Bokeh Server!!!
******* Need to work in separate files
** May 21 in NYC <2017-05-21 Sun>                                       :day:
*** Bokeh Revelation
**** Get Data
**** Make Plot
**** Update Plot/Callback
***** All changes shall happen here
**** Layout
** May 22 in NYC <2017-05-22 Mon>                                       :day:
*** TODO Udacity Deep Learning                         :udacity:deeplearning:
**** Numpy Refresher
***** array operations
#+BEGIN_SRC ipython :session
  import sys
  sys.version
#+END_SRC
 #+BEGIN_SRC python :session
     import numpy as np
     #this block will replace the list
     # Pure python code
     values = list(range(1,5))
     for i in range(len(values)):
	 values[i] += 5
     values

     # this block won't change the list
     values_2 = list(range(1,10))
     for item in values_2:
	 item += 5

     values_2
     # Numpy code
     values_3 = np.array(values)+5
     # now values_3 is an ndarray that holds [6,7,8,9,10]
     values_3

     a = np.array([[1,2],[3,4]])
     a.shape
 #+END_SRC

 #+RESULTS:
 | 2 | 2 |
***** Matrix Product
#+BEGIN_SRC python :session
  import numpy as np

  arr1 = np.array([0,2,4,6])
  arr2 = np.array([1,7,13,19])

  arr3 = np.multiply(arr1, arr2)

  arr3

  var = np.dot(arr1, arr2)
  var
#+END_SRC

#+RESULTS:
: 180
***** Dot Product
#+BEGIN_SRC python :session
  import numpy as np

  mat1 = np.matrix([[0,2,4,6],[8,10,12,14]])
  mat2 = np.matrix([[1,3,5],[7,9,11],[13,15,17],[19,21,23]])

  var = np.dot(mat1, mat2)

  var
#+END_SRC

#+RESULTS:
| 180 | 204 | 228 |
| 500 | 588 | 676 |
***** number of cols on left = number of rows on the right
***** matrix mult: a table of dot products
***** It turns out that the results of dot and matmul are the same if the matrices are two dimensional.
#+BEGIN_SRC python :session
  import numpy as np

  a = np.array([[1,2,3,4],[5,6,7,8]])
  b = np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])

  c = np.matmul(a, b)
  c

  d = np.dot(a,b)
  d
#+END_SRC

#+RESULTS:
|  70 |  80 |  90 |
| 158 | 184 | 210 |
***** matrix transpose can be used safely in a matrix multiplication if the data in both original matrices is arranged as rows

#+BEGIN_SRC ipython :session
  import numpy as np
  m = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])

  print(m)
  print(m.T)
  print(np.transpose(m))

  inputs = np.array([[-0.27,  0.45,  0.64, 0.31]])

  weights = np.array([[0.02, 0.001, -0.03, 0.036], \
      [0.04, -0.003, 0.025, 0.009], [0.012, -0.045, 0.28, -0.067]])

  print(inputs.min())

  print(np.matmul(inputs, weights.T))

  print(np.matmul(weights, inputs.T))
#+END_SRC

#+RESULTS:
**** DONE Conda Virtual Env
***** Create an environment
****** conda create -n (env_name) python=3: create a conda environment specifying python version is 3
****** source activate (env_name): activate environment
****** conda list: list all the installed packages
***** list all environment
****** conda info --envs
***** Remove an environment
****** conda remove --name (env_name) --all
***** Export to a yaml file
****** conda env export > environment.yaml
***** Load yaml file
****** conda env create -f environment.yaml
**** DONE Application
***** [[file:~/Dropbox/DeepLearning/fast-style-transfer/style-transfer-out/][Style Transfer]]
***** Deep Traffic
****** [[http://selfdrivingcars.mit.edu/][Self-Driving Car Course at MIT]]
***** [[https://github.com/yenchenlin/DeepLearningFlappyBird][Flappy Bird]]
***** Books
****** [[file:~/Dropbox/DeepLearning/Book/Grokking_Deep_Learning_v6_MEAP.pdf][Grokking Deep Learning]]
****** [[http://neuralnetworksanddeeplearning.com/index.html][Neural Networks and Deep Learning]]
****** [[http://www.deeplearningbook.org/][MIT Deep Learning Book]]
**** TODO Regression                                                   :todo:
*** TODO AVA Functions
**** [[http://apps.appliedvalueanalytics.com][Current Link]]
**** TODO Data Cleansing
***** DONE Added tax rate
***** DONE Changed NOPAT, NOPAT%
***** DONE Add WACC Page
***** DONE Add ROIC
***** DONE Adde EVA
**** Idea Generation
**** Company Charts integrate to load data
**** Full, low, high tables
**** User management
***** Refer to the flask class again
***** [[https://www.youtube.com/watch?v=ItzVQGht-Es&list=PLQVvvaa0QuDc_owjTbIY4rbgXOFkUYOUB&index=15][User Registration]]
*** TODO Optimization
**** Model Validation
*** Emacs
**** [[http://ergoemacs.org][Ergo Emacs]]
** May 23 in NYC <2017-05-23 Tue>                                       :day:
*** TODO Udacity Deep Learning                         :udacity:deeplearning:
**** TODO Regression
***** [[http://pandas.pydata.org/pandas-docs/stable/10min.html#min][10 Minutes to Pandas]]
#+BEGIN_SRC ipython :session
  import sys
  sys.version
#+END_SRC

#+RESULTS:
: 3.6.0 |Anaconda 4.3.1 (64-bit)| (default, Dec 23 2016, 12:22:00) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]

#+BEGIN_SRC ipython :session :file /home/isaac/Documents/image.svg :exports both
  %matplotlib inline
  %config InlineBackend.figure_format = 'svg'
  import pandas as pd
  import numpy as np
  import matplotlib.pyplot as plt

  # creating a series

  ts = pd.Series(np.random.randn(1000), index=pd.date_range("1/1/2010", periods = 1000))
  ts = ts.cumsum()
  ts.plot()
#+END_SRC

#+RESULTS:
[[file:/home/isaac/Documents/image.svg]]

***** [[http://scikit-learn.org/stable/tutorial/basic/tutorial.html][Intro to Scikit-learn]]
***** [[http://matplotlib.org/users/pyplot_tutorial.html][Matplotlib]]
*** TODO AVA Functions
**** TODO Select Data
**** TODO Data table
**** TODO Charts
*** TODO Optimization
**** Build a donut chart for current situation

*** Manjaro                                                            :arch:
**** install: sudo pacman -S [software name]
**** sync and update: sudo pacman -Syyu
*** Emacs                                                             :emacs:
**** reload .init.el file without restarting
***** M-x eval-buffer (when emacs is open)
***** M-x load-file RET ~/.emacs.d/init.el
**** [[https://github.com/gregsexton/ob-ipython/][ob-ipython]]
****** ipython in org-mode
**** [[https://www.youtube.com/watch?v=SzA2YODtgK4][Best Org-Mode Video on Youtube]]
** May 24 in NYC <2017-05-24 Wed>                                       :day:
*** TODO AVA Functions
*** TODO Optimization
#+BEGIN_SRC ipython :session :exports both
  import pandas as pd
  import numpy as np

  from pulp import *

  data_simple = "/home/isaac/Dropbox/OPT/00_steel_info/data_simple.csv"
  df = pd.read_csv(data_simple)
  ## Function to Convert Wide DF to Long DF
  def gather(df, key, value, cols):
      id_vars = [col for col in df.columns if col not in cols]
      id_values = cols
      var_name = key
      value_name = value
      return pd.melt(df, id_vars, id_values, var_name, value_name)

  suppliers = ['TKS', 'Arcelor','Salzgitter']
  df_new = gather(df, "Suppliers", "Quotes", suppliers)

  quotes = df_new["Quotes"]
  volumes = df_new["Volume"]
  supplier = df_new["Suppliers"]

  decision_variables = []

  for rownum, row in df_new.iterrows():
      variable = str('x'+str(rownum))
      variable = pulp.LpVariable(str(variable), cat="Binary")
      decision_variables.append(variable)

  df_new["Decision Variable"] = decision_variables

  dec_vars = df_new["Decision Variable"]

  prob = pulp.LpProblem("Steel OPT", pulp.LpMinimize)
  total_npv = np.sum(volumes * quotes * dec_vars)

  prob += total_npv

  prob += dec_vars[0] + dec_vars[3] + dec_vars[6] == 1
  prob += dec_vars[1] + dec_vars[4] + dec_vars[7] == 1
  prob += dec_vars[2] + dec_vars[5] + dec_vars[8] == 1

  opt_results = prob.solve()

  #reorder results
  variable_name = []
  variable_value = []

  for v in prob.variables():
	  variable_name.append(v.name)
	  variable_value.append(v.varValue)

  df_new["Decision Results"] = variable_value

  win_data = df_new[df_new["Decision Results"] ==1]
  win_data

  prob
#+END_SRC

#+RESULTS:
#+begin_example
Steel OPT:
MINIMIZE
2092090*x0 + 150875*x1 + 38764*x2 + 2204950*x3 + 148625*x4 + 54120*x5 + 2466200*x6 + 140875*x7 + 42944*x8 + 0
SUBJECT TO
_C1: x0 + x3 + x6 = 1

_C2: x1 + x4 + x7 = 1

_C3: x2 + x5 + x8 = 1

VARIABLES
0 <= x0 <= 1 Integer
0 <= x1 <= 1 Integer
0 <= x2 <= 1 Integer
0 <= x3 <= 1 Integer
0 <= x4 <= 1 Integer
0 <= x5 <= 1 Integer
0 <= x6 <= 1 Integer
0 <= x7 <= 1 Integer
0 <= x8 <= 1 Integer
#+end_example
** May 25 in NYC <2017-05-25 Thu>                                       :day:
*** TODO Optimization & Prep for Updates
*** TODO AVA Webapp
*** TODO IT Structure
|-------------+----------------------------------------------------------------------------+----------------------+------------------------------+----------+--------|
| Options     | Description                                                                | Pro                  | Cons                         |  ETA(wk) | Gap    |
|-------------+----------------------------------------------------------------------------+----------------------+------------------------------+----------+--------|
| Pure Excel  | 1. Use Gus Excel Template.                                                 | Simple, Done;        | High Admin Costs             |        0 | None   |
|             | 2. Excel only Aggregation, no vba involved                                 | No need for AVA      |                              |          |        |
|-------------+----------------------------------------------------------------------------+----------------------+------------------------------+----------+--------|
| Excel VBA 1 | 1. Users use regular excel template;                                       | Simple;              | Submit process not automated |        1 | None   |
|             | 2. Admin aggregate with built in macros                                    | limited AVA support  |                              |          |        |
|-------------+----------------------------------------------------------------------------+----------------------+------------------------------+----------+--------|
| Excel VBA 2 | 1. Users use excel vba with click button/send to sharepoint                | Moderately Simple;   | None                         |      1.5 | None   |
|             | 2. Admin use excel master vba to grab files from dropbox and aggregate     | Fair AVA support     |                              |          |        |
|-------------+----------------------------------------------------------------------------+----------------------+------------------------------+----------+--------|
| Excel + Web | 1. User form submit request on web                                         | Relatively automated | Deployment                   |   1+2+1+ | JS     |
|             | 2. Data stored in sqlite on server                                         |                      | Javascript                   |          | JQuery |
|             | 3. Javascript handles submit code on the front, Python connets with sqlite |                      |                              |          | Docker |
|             | 4. Admin can pull aggregated data to excel and manipulate in excel         |                      |                              |          |        |
|-------------+----------------------------------------------------------------------------+----------------------+------------------------------+----------+--------|
| Pure Web    | 1. Similar to the previous option, admin can also see results on web       | Automated, packaged  | Deployment                   |          | JS     |
|             |                                                                            |                      | JS                           |          | JQuery |
|             |                                                                            |                      | Front End design             | 1.5+2+1+ | Design |
|             |                                                                            |                      |                              |          | Docker |
|-------------+----------------------------------------------------------------------------+----------------------+------------------------------+----------+--------|
** May 26 in NYC <2017-05-26 Fri>                                       :day:
*** TODO Optimization Applets
**** [[file:~/Dropbox/OPT/optimization.org][Optimization Org File]]

*** TODO AVA webapp
*** TODO IT requests
*** TODO Pandas Refresher
**** [[https://www.udemy.com/data-analysis-with-pandas/learn/v4/overview][Data Analysis with Pandas and Python]]
**** [[https://www.udemy.com/data-analysis-in-python-with-pandas/learn/v4/overview][Data Analysis in Python with Pandas]]
**** [[https://www.udemy.com/learning-python-for-data-analysis-and-visualization/learn/v4/overview][Learning Python for Data Analysis and Visualization]]
**** [[https://www.udemy.com/python-for-data-science-and-machine-learning-bootcamp/learn/v4/overview][Python for Data Science and Machine Learning Bootcamp]]
*** TODO Bokeh Refresher
**** [[https://www.datacamp.com/courses/interactive-data-visualization-with-bokeh][Datacamp Bokeh]]
**** [[https://www.youtube.com/watch?v=LXLQTuSSKfY][Bokeh SciPy]]
**** [[https://www.youtube.com/watch?v=vWUPs4fNmKQ][Bokeh Strata NYC 2016]]
**** [[https://www.udemy.com/python-bokeh/learn/v4/overview][Udemy Bokeh]]
*** Anaconda Remove
**** conda install anaconda-clean   # install the package anaconda clean
**** anaconda-clean --yes           # clean all anaconda related files and directories
**** rm -rf ~/anaconda3             # removes the entire anaconda directory
**** rm -rf ~/.anaconda_backup       # anaconda clean creates a back_up of files/dirs, remove it
**** conda list; #cmd shouldn't respond after the clean up
*** TODO Javascript
*** PuLP
**** [[file:~/Dropbox/OPT/PuLP/PulP%20Intro.pdf][Book]]
*** TODO Docker
**** [[https://www.udemy.com/the-docker-for-devops-course-from-development-to-production/learn/v4/t/lecture/3937984?start=0][Docker Udemy]]
***** Install Docker
****** [[http://apt.dockerproject.org/repo/pool/main/d/docker-engine/][Docker Enging]]
****** Use 1.83 trusty
****** Install docker dependencies: sudo apt-get install libapparmor1 aufs-tools ca-certificates
****** sudo dpkg -i [docker image]
****** grand su permission: sudo usermod -aG docker isaac
****** reboot
***** Docker Compose
****** [[https://github.com/docker/compose/releases][Docker Compose Github Repo]]
****** curl -L https://github.com/docker/compose/releases/download/1.4.2/docker-compose-Linux-x86_64 > /tmp/docker-compose
****** cd /tmp/
****** chmod +x docker-compose # Make docker-compose executable
****** sudo mv docker-compose /usr/local/bin/ #move the file to local/usr/bin
***** Run Docker
****** docker run --rm busybox:latest /bin/echo "Hello World!"
****** busybox is an extremely small linux distro
****** docker --help see all the commands
****** docker images: check all the images downloaded
****** docker ps: check all the running containers
****** docker run busybox:latest /bin/echo "Hello World!"
****** docker ps -a : will show all the containers
****** docker rm [container id] will remove the containers manually
****** docker run -it --rm busybox:latest: check what's inside the busybox image -it means run it interactively
****** C-d will exit the docker run
****** docker rmi [image id] will delete existing images
****** docker images are imutable
***** Docker Registry
****** Similar to github
***** Dockerized web app
****** Set up a proj directory
***** Dockerized Flask app
****** [[file:~/Dropbox/Projects/][Project Folder Location]]
****** Project Scaffolding
└── MobyDock
    └── mobydock
        ├── config
        │   ├── __init__.py
        │   └── [[file:~/Dropbox/Projects/MobyDock/mobydock/config/settings.py][settings.py]]
        ├── docker-compose.yml
        ├── Dockerfile
        ├── instance
        │   ├── __init__.py
        │   └── settings.py.production_example
        ├── mobydock
        │   ├── [[file:~/Dropbox/Projects/MobyDock/mobydock/mobydock/app.py][app.py]]
        │   ├── __init__.py
        │   ├── static
        │   │   ├── logo.png
        │   │   └── main.css
        │   └── templates
        │       └── layout.html
        └── requirements.txt
****** Dockerfile
******* A recipe to build the docker image
******* [[file:~/Dropbox/Projects/MobyDock/mobydock/Dockerfile][Dockerfile Details]]
****** Requirements file
******* [[file:~/Dropbox/Projects/MobyDock/mobydock/requirements.txt][Requirements file details]]
****** Git ignore file
******* [[file:~/Dropbox/Projects/MobyDock/mobydock/.gitignore][.gitignore file details]]
****** Docker ignore file
******* [[file:~/Dropbox/Projects/MobyDock/mobydock/.dockerignore][.dockerignore file details]]
****** Docker-compose
******* [[file:~/Dropbox/Projects/MobyDock/mobydock/docker-compose.yml][docker-compose]]
******* docker-compose up
****** Create Database
******* docker exec mobydock_postgres_1 createdb -U postgres mobydock
******* docker exec mobydock_postgres_1 psql -U postgres -c "CREATE USER mobydock WITH PASSWORD 'yourpassword'; GRANT ALL PRIVILEGES ON DATABASE mobydock to mobydock;"
** May 27 in NYC <2017-05-27 Sat>                                       :day:
*** Docker
*** HTML+CSS+JS
*** Python Numpy
*** Python Pandas
*** Python Bokeh
*** R
**** [[https://www.datascienceriot.com/how-to-install-r-in-linux-ubuntu-16-04-xenial-xerus/kris/][Install R and R Studio on Ubuntu]]
**** [[http://orgmode.org/worg/org-contrib/babel/languages/ob-doc-R.html][Use R in Emacs Org-Mode]]
#+begin_src R :session
library(lattice)
xyplot(1:10 ~ 1:10)
#+end_src

#+RESULTS:
*** [[https://www.lynda.com/Flask-tutorials/Learning-Flask/521231-2.html][Flask]]
*** [[https://www.digitalocean.com/community/tutorials/how-to-install-and-use-postgresql-on-ubuntu-16-04][PostgreSQL]]
**** sudo -u postgres createdb databasename
**** to access a postgres prompt: sudo -i -u postgres
**** psql
**** connet to a database: \c databasename
**** to quit: \q
** May 28 in NYC <2017-05-28 Sun>                                       :day:
*** [[https://www.youtube.com/watch?v=ZdDOauFIDkw][Python Regular Expression]]
#+BEGIN_SRC ipython :session
  import re
  print(re.split(r'[a-z]*(@appliedvalue.com)', "isaac.zhou@appliedvalue.com"))
#+END_SRC

#+RESULTS:
*** Postgresql
**** [[https://help.ubuntu.com/community/PostgreSQL#fe_sendauth:_no_password_supplied][Need to set up the password]]
*** OrgMode
**** Yasnippet
**** Beautify Export
***** [[https://github.com/fniessen/org-html-themes][org-html-themes(downloaded)]]
***** [[http://demo.thi.ng/org-spec/][A Very Good Example]]
*** Pandas
*** Numpy
**** Create Arrays from Python Structure
***** Check Numpy Version
#+BEGIN_SRC ipython :session :file  :exports both
   import numpy as np
   np.__version__
#+END_SRC

#+RESULTS:
: 1.11.3

***** Create From a Python List
#+BEGIN_SRC ipython :session :file  :exports both
  my_list = [-17,0,4,5,9]
  my_array = np.array(my_list)
  my_list
  my_list * 10
  my_array
  my_array * 10
#+END_SRC

#+RESULTS:
: array([-170,    0,   40,   50,   90])

***** Create From a Tuple
#+BEGIN_SRC ipython :session :file  :exports both
  my_tuple = (14,3.54,5+7j)
  np.array(my_tuple)
  #Note the promotion of the data type
#+END_SRC

#+RESULTS:
: array([ 14.00+0.j,   3.54+0.j,   5.00+7.j])

***** Difference between Python and Numpy Data Structure
#+BEGIN_SRC ipython :session :file  :exports both
  print(my_tuple * 6)
  print(np.array(my_tuple) * 6)
#+END_SRC

#+RESULTS:

**** Intrinsic Numpy Array Creation: 
***** Arange
#+BEGIN_SRC ipython :session :file  :exports both
   np.arange(7)
   np.arange(3,19,3)
   len(np.arange(3,19,3))
   np.arange(3,19,3).size
#+END_SRC

#+RESULTS:
: 6

***** linspace, zeros, ones
#+BEGIN_SRC ipython :session :file /media/sf_host/Dropbox/OrgEmacs/images/image.png :exports both
  %matplotlib inline
  import matplotlib.pyplot as plt
  import numpy as np

  x = np.linspace(8,12,100)
  y = np.cos(x)

  plt.plot(x, y)
  plt.show()
#+END_SRC

#+RESULTS:
[[file:/media/sf_host/Dropbox/OrgEmacs/images/image.png]]
#+BEGIN_SRC ipython :session :file /media/sf_host/Dropbox/OrgEmacs/images/image2.png  :exports both
  import numpy as np
  import matplotlib.pyplot as plt
  %matplotlib inline

  x = np.linspace(0,10,200)
  y = np.sin(x)

  plt.plot(x,y)
#+END_SRC

#+RESULTS:
[[file:/media/sf_host/Dropbox/OrgEmacs/images/image2.png]]
#+BEGIN_SRC ipython :session :file /media/sf_host/Dropbox/OrgEmacs/images/1.png :exports both
  x = np.ones(100)
  y = np.zeros(100)
  plt.plot(x)
  plt.plot(y)
#+END_SRC

#+RESULTS:
[[file:/media/sf_host/Dropbox/OrgEmacs/images/1.png]]
**** Index, Slice and Iterate
***** Slice Arrays
#+BEGIN_SRC ipython :session  :exports both
  import numpy as np
  my_vec = np.array([-17, -4, 0, 2, 21, 37, 105])
  my_vec[-3]
  my_arr = np.arange(36)
  my_arr.shape=(6,6)
  my_arr
  my_arr_3d = np.arange(36)
  my_arr_3d.shape = (4,3,3)
  my_arr_3d[3][2][1]
#+END_SRC

#+RESULTS:
: 34
***** Boolean Mask Arrays
#+BEGIN_SRC ipython :session :exports both
  import numpy as np
  my_vec = np.arange(107)
  zero_mod_7_mask = (my_vec%7)==0
  # Python way
  zero_mod_7 = my_vec[zero_mod_7_mask]
  zero_mod_7

  # Numpy logical function Faster on bigger dataset
  zero_mod_7_np = my_vec[np.logical_and(my_vec, zero_mod_7_mask)]
  zero_mod_7_np
#+END_SRC

#+RESULTS:
: array([  7,  14,  21,  28,  35,  42,  49,  56,  63,  70,  77,  84,  91,
:         98, 105])
***** Broadcasting
#+BEGIN_SRC ipython :session  :exports both :results output
  import numpy as np
  my_3d_arr = np.arange(70)
  my_3d_arr.shape=(2,7,5)
  print(my_3d_arr)
  print(my_3d_arr.shape)
  print(my_3d_arr.ndim)
  print(my_3d_arr.size)
  my_3d_arr.dtype
#+END_SRC

#+RESULTS:
#+begin_example
[[[ 0  1  2  3  4]
  [ 5  6  7  8  9]
  [10 11 12 13 14]
  [15 16 17 18 19]
  [20 21 22 23 24]
  [25 26 27 28 29]
  [30 31 32 33 34]]

 [[35 36 37 38 39]
  [40 41 42 43 44]
  [45 46 47 48 49]
  [50 51 52 53 54]
  [55 56 57 58 59]
  [60 61 62 63 64]
  [65 66 67 68 69]]]
(2, 7, 5)
3
70
#+end_example

#+BEGIN_SRC ipython :session   :exports both
5 * my_3d_arr -2
left_mat = np.arange(6).reshape(2,3)
right_mat = np.arange(15).reshape((3,5))
np.dot(left_mat, right_mat)
#+END_SRC

#+RESULTS:
: array([[ 25,  28,  31,  34,  37],
:        [ 70,  82,  94, 106, 118]])
***** Operation align Axis
#+BEGIN_SRC ipython :session   :exports both
my_3d_arr.sum(axis=0)
my_3d_arr.sum(axis=1)
my_3d_arr.sum(axis=2)
#+END_SRC

#+RESULTS:
: array([[ 10,  35,  60,  85, 110, 135, 160],
:        [185, 210, 235, 260, 285, 310, 335]])
***** Broadcasting Rules
#+BEGIN_SRC ipython :session   :exports both
  my_2d_arr = np.ones(35, dtype="int_").reshape(7,5) * 3
  my_2d_arr

  my_2d_rand = np.random.random((7,5))
  my_2d_rand

  np.set_printoptions(precision=4)
  my_2d_arr * my_2d_rand
#+END_SRC

#+RESULTS:
: array([[ 0.5301,  0.1486,  1.6033,  1.3311,  0.3094],
:        [ 0.325 ,  2.1556,  1.6545,  2.9889,  0.2198],
:        [ 2.5073,  1.777 ,  2.6875,  2.2024,  0.1658],
:        [ 1.3208,  1.9284,  2.7465,  0.4788,  1.6379],
:        [ 2.6463,  2.5374,  0.1929,  2.6908,  0.5791],
:        [ 0.8695,  1.4823,  0.0798,  1.2452,  1.389 ],
:        [ 2.2688,  0.06  ,  1.6476,  1.5242,  0.2611]])
**** Matplotlib
***** Inline Plotting
 #+BEGIN_SRC ipython :session :file /media/sf_host/Dropbox/OrgEmacs/images/image.svg  :exports both
   %matplotlib inline
   %config InlineBackend.figure_format = 'svg'

   import numpy as np
   import matplotlib.pyplot as plt
   mu, sigma = 100, 15
   data_set = mu + sigma * np.random.randn(10000)

   n, bins, patches = plt.hist(data_set, 100, normed=1, facecolor='r', alpha=0.75)

   plt.xlabel('Smarts')
   plt.ylabel('Probability')
   plt.show()
 #+END_SRC

 #+RESULTS:
 [[file:/media/sf_host/Dropbox/OrgEmacs/images/image.svg]]
** May 29 in NYC <2017-05-29 Mon>                                       :day:
*** TODO IT Request
**** User Mode
***** Project Request Input
***** Save on Sharepoint
***** Email
**** Admin Mode
***** Load Projects from Sharepoint
***** Edit Projects --> Database
***** Database --> Analytics
***** Analytics --> PDF
** May 30 in NYC <2017-05-30 Tue>                                       :day:
*** TODO AVA Web Apps
#+BEGIN_SRC ipython :session :file  :exports both
  import numpy as np
  import pandas as pd

  df = pd.read_csv("/home/isaac/Dropbox/AVA/Data_CSV/FQ/ROIC.csv")

  df.info()
#+END_SRC

#+RESULTS:

#+BEGIN_SRC ipython :session :file  :exports both
  df_new = df[(df["AV Sector"] == "Auto OEM") & (df["Country"]=="United States")]
  df_pivot = df_new.pivot(index = "Period", columns = "Company Name", values="ROIC")
#+END_SRC

#+RESULTS:


#+BEGIN_SRC ipython :session :file  :exports both
  df_new.pivot_table(values="ROIC", index=["Period", "Company Name"], aggfunc=lambda x: np.percentile(x, 50))
#+END_SRC
** May 31 in NYC <2017-05-31 Wed>                                       :day:
*** TODO AVA Web Apps
Remove outliers
#+BEGIN_SRC ipython :session :file  :exports both
  import numpy as np
  import pandas as pd

  df = pd.read_csv("/home/isaac/Dropbox/AVA/Data_CSV/FQ/NOPAT%.csv")

  df.info()
#+END_SRC

#+RESULTS:

#+BEGIN_SRC ipython :session :file  :exports both
  df_new = df[(df["AV Sector"] == "Auto OEM") & (df["Country"]=="United States")]
  df_pivot = df_new.pivot(index = "Period", columns = "Company Name", values="NOPAT%")
  print(df_pivot.ix["2012-Q-4"])
  print(df_pivot.ix["2012-Q-3"])
  df_pivot.ix["2012-Q-4"][df_pivot.ix["2012-Q-4"] / df_pivot.ix["2012-Q-3"] -1 < 0.5]
#+END_SRC

#+RESULTS:
: Company Name
: Ford Motor Company (NYSE:F)           0.018916
: Harley-Davidson, Inc. (NYSE:HOG)      0.070051
: Tesla Motors, Inc. (NasdaqGS:TSLA)   -0.296198
: Thor Industries, Inc. (NYSE:THO)      0.049243
: Name: 2012-Q-4, dtype: float64

#+BEGIN_SRC ipython :session :file  :exports both
  df_new.pivot_table(values="ROIC", index=["Period", "Company Name"], aggfunc=lambda x: np.percentile(x, 50))
#+END_SRC

#+BEGIN_SRC ipython :session :file  :exports both
  df_pivot_new = df_pivot.copy()
  for col in df_pivot_new.columns:
      for i in range(1, len(df_pivot_new.index)):
          if np.abs(df_pivot_new[col].ix[i]/df_pivot_new[col].ix[i-1] - 1) > 0.5:
              df_pivot_new[col].ix[i] = np.nan
          else:
              df_pivot_new[col].ix[i] = df_pivot[col].ix[i]
          print(col)
          print(np.abs(df_pivot_new[col].ix[i]/df_pivot_new[col].ix[i-1] - 1))

  df_pivot_new
#+END_SRC

#+BEGIN_SRC ipython :session :file  :exports both
  df_pivot_new = df_pivot.copy()
  df_q3 = df_pivot_new.quantile(0.75)
  df_q1 = df_pivot_new.quantile(0.25)
  df_iqr = df_q3 - df_q1
  df_iqr

  for col in df_pivot_new.columns:
      for i in df_pivot_new.index:
          if (df_pivot_new[col].ix[i] < (df_q1[col] - 1.5 * df_iqr[col])) or (df_pivot_new[col].ix[i] > (df_q3[col] + 1.5 * df_iqr[col])):
              df_pivot_new[col].ix[i] = np.nan

  df_pivot_new.quantile(0.2, axis=1)
#+END_SRC

#+RESULTS:
#+begin_example
Period
2012-Q-1    0.034907
2012-Q-2    0.030372
2012-Q-3    0.032734
2012-Q-4   -0.107130
2013-Q-1    0.014912
2013-Q-2    0.024491
2013-Q-3    0.027518
2013-Q-4    0.019933
2014-Q-1   -0.000348
2014-Q-2    0.002093
2014-Q-3    0.011455
2014-Q-4    0.006260
2015-Q-1    0.013894
2015-Q-2    0.034399
2015-Q-3    0.035733
2015-Q-4   -0.006624
2016-Q-1    0.039319
2016-Q-2    0.035381
2016-Q-3    0.033714
2016-Q-4    0.038119
2017-Q-1    0.026970
Name: 0.2, dtype: float64
#+end_example
*** Docker Installation
**** Install Docker 1.8.3
***** Check docker images: docker images
***** Check docker containers: docker ps -a
**** Install Docker compose 1.4.2
***** curl -L https://github.com/docker/compose/releases/download/1.4.2/docker-compose-Linux-x86_64 > /tmp/docker-compose
***** cd /tmp/
***** chmod +x docker-compose
***** sudo mv docker-compose /usr/local/bin/
**** Build a dockerized app
***** folder structure
****** touch requirement.txt
****** touch .gitignore
****** touch Dockerfile: recipe of building docker image
****** touch docker-compose.yml
****** touch .dockerignore
****** mkdir instance
******* touch instance/__init__.py
******* touch instance/settings.py.production_example
****** mkdir config
******* touch config/__init__.py
******* touch config/settings.py
***** 
* 2017-June-Log
** June 5 in NYC <2017-06-05 Mon>                                       :day:
*** [[file:~/Dropbox/DeepLearning/2_CNN/CNN.org][Deep Learning]]
*** Emacs Meetup
**** Ligtning Talk
***** [[https://www.emacswiki.org/emacs/TrampMode][Tramp]]: ssh for remote machine control
***** [[http://www.flycheck.org/en/latest/][Flycheck]]: syntax checker
***** Googler-search: cool link generation
***** Cool shell commands
****** Shpotify
****** pianobar
****** fast
****** cmus
****** Youtube-dl
****** tra fr:
***** user select package
** June 6 in NYC <2017-06-06 Tue>                                       :day:
*** [[http://www.tendereasy.com/en-GB/solutions/freight-tendering-21521045?gclid=Cj0KEQjwmcTJBRCYirao6oWPyMsBEiQA9hQPbgowiAXvAzuceYXPDeEbZSO9w1fSHOq2sg5cL8xK8P8aAo9f8P8HAQ][TenderEasy]]
**** [[http://www.tendereasy.com/en-GB/story-33907212][Timeline]]: 
- 4 years to transform from a consultancy to an e-sourcing SW
- another 4 years to launch the platform and onboard first customer
*** [[http://www.appliedvaluegroup.com/applied-vc-growth-capital#garden-growth-capital-1][Portfolio Company]] --> Reach out for demo (email Manuel)
*** Fake it until we do it
**** Build the website (Integrate with Current [[http://www.appliedvalueanalytics.com/][AVA website]]) which fully illustrates our philosophy and methodology
**** Highlight the Deep Learning and AI features
**** Start selling generic optimization consultancy/SW before we actually build THE platform
*** [[file:~/Dropbox/OPT/optimization.org][AV Optimization]]
**** Model Validation
**** UI
*** [[http://appliedvalueanalytics.com/][Front End]]
**** Building while training(skeleton done)
**** Gap closing
*** Adjusted AVA Timeline
**** Load all basic ROIC apps (this week) <2017-06-09 Fri>
**** Analytics Optimization Web Sekleton (3 weeks, including this week) <2017-06-23 Fri>
**** Building Optimization Applets(4 weeks, 1 steel + 8~9 others) <2017-07-28 Fri>
**** Polishing UI + Formalize Process(4 weeks) <2017-08-25 Fri>
**** Selling <2017-09-15 Fri> while building the platform <2018-06-22 Fri>
** June 7 in NYC <2017-06-07 Wed>                                       :day:
*** TODO App Implementation
**** Gapminder 
**** Pivot
**** Export Data
*** 
** June 8 in NYC <2017-06-08 Thu>                                       :day:
*** Github revisited
**** new repo -> git init
**** add .gitignore
**** create repo on github
**** git remote add origin git@github.com:username/reponame.git
**** git push -u origin master
*** Algorithms in Python
** June 10 in NYC <2017-06-10 Sat>                                      :day:
*** RNN
*** [[https://www.youtube.com/watch?v=NfnWJUyUJYU][Convolutional Neural Networks for Visual Recognition]]
*** [[https://www.youtube.com/watch?v=UzxYlbK2c7E&list=PLA89DCFA6ADACE599][Machine Learning]]
*** [[https://www.coursera.org/learn/machine-learning/home/welcome][Machine Learning Coursera]]
*** [[https://www.coursera.org/learn/neural-networks/home/welcome][Neural Networks]]
** June 11 in NYC <2017-06-11 Sun>                                      :day:
*** Sphinx (Not for me)
**** sphinx-build
**** sphinx-quickstart doc
*** Pelican
**** Install Pelican and Markdown
- pip install pelican
- pip install markdown
*** Blog Strategy
**** Static
**** Homepage: HTML+CSS+JS
**** Sections: Org-mode export
** June 12 in NYC <2017-06-12 Mon>                                      :day:
*** AVA On Board
**** DONE Goals: Major Update in 11 days <2017-06-23 Fri>
***** Steel Optimizer: Validation and Basic UI
***** AVA Webapp
***** Optimization Applets
**** DONE Bokeh: AVA Webapp
***** [[http://bokeh.pydata.org/en/latest/][Bokeh]]
**** [[file:~/Dropbox/OPT/optimization.org][Steel Optimization]]
**** DONE Optimization Applets: Lindo + PulP
***** [[https://pythonhosted.org/PuLP/][Pulp]]
**** Purchasing Analytics
***** [[http://www.tendereasy.com/en-GB/story-33907212][TenderEasy]]
*** TODO Tasks
**** TODO Finish all AVA apps <2017-06-12 Mon>
***** ROIC
***** Data table download
***** Idea Generation
***** Data validation
**** TODO Steel optimization <2017-06-14 Wed>
***** Results validation
***** Basic UI
**** Optimization Applets(Linear) <2017-06-16 Fri>
***** Blending Models
***** Media Buying
***** Inventory Management
***** Product Mix
***** Building Block Method
***** Waste minization
***** Plant locating
***** Staff scheduling
***** Transportation Models
**** Optimization Applets Requirements
***** Control
***** Visualized Output
** June 13 in NYC <2017-06-13 Tue>                                      :day:
*** Tensorboard
*** Data Portfolio
**** [[http://www.kdnuggets.com/2016/07/five-big-data-projects-cant-overlook.html][Build a Data Portfolio]]
**** [[https://www.dataquest.io/blog/how-to-setup-a-data-science-blog/][Build a Data Blog]]
**** [[https://www.dataquest.io/blog/build-a-data-science-portfolio/][Build a Data Portfolio to get Job]]
*** Data Blog with Jupyter Notebook
**** Install Pelican
**** pelican quickstart
**** Install the Jupyter plugin
**** modify pelicanconf.py
**** Create A Jupyter Notebook
**** Copy the notebook into the content folder
**** Create a file has the same name as your notebook, but the extension .ipynb-meta
** June 14 in NYC <2017-06-14 Wed>                                      :day:
*** Pelican Deployment
**** local: pelican content
**** website: pelican content -s publishconf.py
*** R for Jupyter Notebook
**** sudo apt-get install libcurl4-openssl-dev libssl-dev
**** install.packages(c('repr', 'IRdisplay', 'evaluate', 'crayon', 'pbdZMQ', 'devtools', 'uuid', 'digest'))
**** devtools::install_github('IRkernel/IRkernel')
**** IRkernel::installspec()
** June 15 in NYC <2017-06-15 Thu>                                      :day:
*** sudo chown -R usr foldername
** June 16 in NYC <2017-06-16 Fri>                                      :day:
*** Pandas
*** Idea Generation
** June 25 in NYC <2017-06-25 Sun>                                      :day:
*** [[http://blog.csdn.net/young_gy/article/details/73412285][Udacity Translation]]
** June 28 in NYC <2017-06-28 Wed>                                      :day:
*** Pelican personal blog
**** Setup
**** Python
***** [[https://www.datacamp.com/courses/python-data-science-toolbox-part-1][Functions]]
***** Lambda
***** List/Dictionary Comprehension
**** Numpy
***** Lynda + Udemy
**** Pandas
* 2017-July-Log
** July 5 in NYC <2017-07-05 Wed>                                       :day:
*** Pelican Publish Process
**** pelican -s publishconf.py -t ../pelican-chameleon/ content/
**** git status
**** git add .
**** git commit -m ""
**** git push -u origin dev
**** ghp-import output -b master
**** git push origin master
*** Change Ownership
**** chown -R USERNAME: /PATH/TO/FILE
**** chmod -R 755 /Folder
*** Jupyter Notebook SQL
**** conda install -c conda-forge ipython-sql=0.3.6
**** [[https://github.com/catherinedevlin/ipython-sql][Ipython-SQL]]
** July 16 in NYC <2017-07-16 Sun>                                      :day:
html
#+BEGIN_SRC ipython :session :file  :exports both
import numpy as np
#+END_SRC
** July 19 in NYC <2017-07-19 Wed>                                      :day:
** July 21 in NYC <2017-07-21 Fri>           :day:
*** Pelican Blog Publication
- source activate pelican
- pelican -s publishconf.py -t ../pelican-chameleon/ content/
- git add .
- git commit -m "..."
- git push origin dev
- ghp-import output -b master
- git push origin master

** July 23 in NYC <2017-07-23 Sun>                                      :day:
*** Preferred setup
**** text editor: emacs
**** .bashrc
**** python: Anaconda python 3
**** [[https://github.com/dunovank/jupyter-themes][jupyter themes]]

** July 24 in NYC <2017-07-24 Mon>                                      :day:
*** Git reset
- git reflog
- git reset --hard #reflog id#
** July 25 in NYC <2017-07-25 Tue>                                      :day:
*** conda best practices
- Using environments
  - One thing that’s helped me tremendously is having separate environments for Python 2 and Python 3.
  - I used conda create -n py2 python=2 and conda create -n py3 python=3 to create two separate environments, py2 and py3.
  - Now I have a general use environment for each Python version.
  - In each of those environments, I've installed most of the standard data science packages (numpy, scipy, pandas, etc.). Remember that when you set up an environment initially, you'll only start with the standard packages and whatever packages you specify in your conda create statement.
*** testing ob-ipython
#+BEGIN_SRC ipython :session :file ~/Dropbox/1.png  :exports both
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
plt.plot(np.random.randn(1000))
#+END_SRC

#+RESULTS:
[[file:~/Dropbox/1.png]]
** July 26 in NYC <2017-07-26 Wed>           :day:
** July 28 in NYC <2017-07-28 Fri>           :day:
*** Feedback
 - [ ] Run with real data, BMW, Miele
   - mill 100%
   - easy way to add constraints
   - UI/UX for real product, what's needed for the tweak, adjustment
   - 
 - [ ] csv template/ data
 - [ ] Dynamic margin management

** July 29 in NYC <2017-07-29 Sat>                                      :day:

*** A list of data science blogs
- [[https://github.com/rushter/data-science-blogs][Data Science Blog]]
* 2017-Aug-log
** Aug 4 in NYC <2017-08-04 Fri>             :day:
*** Data Science
**** Programming
***** Python
****** Original
****** Numpy
****** Pandas
****** Matplotlib/Seaborn/Bokeh
***** R
***** SQL
***** Scala (L)
**** Data Science Theory
***** Machine Learning
***** Deep Learning
***** Elastic Search
**** Statistics
***** EDA
***** Correlation and Regression
***** Inference
**** Domain Knowledge
***** Optimization
***** Finance
*** Web
**** Front End
***** HMTL+CSS
***** Javascript
***** JQuery
***** React
**** Visualization
***** D3.js
***** DC.js
**** Webframework
***** flask
***** Django (L)
*** Others
**** Linux
**** Emacs
**** Latex
**** Dev Ops
** Aug 14 in NYC <2017-08-14 Mon>
** Aug 15 in NYC <2017-08-15 Tue> 
** Aug 16 in NYC <2017-08-16 Wed>
** Aug 17 in NYC <2017-08-17 Thu>
** Aug 18 in NYC <2017-08-18 Fri>
** Aug 19 in NYC <2017-08-19 Sat>            :day:
** Aug 20 in NYC <2017-08-20 Sun>            :day:
** Aug 21 in NYC <2017-08-21 Mon>            :day:
*** ROIC Training Agenda
    - [X] Intro & Instrallation

      - [X] [[https://www.capitaliq.com/ciqdotnet/downloads/downloads.aspx][Download Link]]

      - [X] [[https://appliedvalue.app.box.com/file/183266146912][Login Info]]

    - [X] ROIC Fundamentals

      - [X] Example

      - [X] Fundamentals

        - [X] Theory

        - [X] Finding peers

        - [X] Populate Model

        - [X] Double Check

        - [X] Populate Slides

        - [X] Synthesis Power Slide

      - [X] Standard Template Excel

      - [X] Standard Template PPT

      - [X] Double Check the Quality and Accuracy

    - [X] Advanced Tool Use

      - [X] Financial Analysis in Bulk

      - [X] AVA Analytics Webapp
        
*** OPT Discussion
** Aug 22 in NYC <2017-08-22 Tue>            :day:
*** D3
**** Plurasight
**** Lynda
** Aug 23 in NYC <2017-08-23 Wed>
*** ROIC Feedback
**** Slides
- [ ] 
**** ROIC Calculation
** Aug 25 in NYC <2017-08-25 Fri>
*** Tasks
| To-dos      | Actions                                 | ETA |
|-------------+-----------------------------------------+-----|
| DC.js       | Finish DC.js from Lynda                 | 5H  |
| Semantic UI | Finish Semantic UI 2.0 from Pluralsight | 4H  |
- [ ] Create a bar chart: payment types
  - [ ] Create div placeholder within html
  - [ ] Organize the data with crossfilter
  - [ ] Declare charts in DC

| Action Items | Details | ETA |
|--------------+---------+-----|
|              |         |     |

<div id="bar-chart-payment-by-type">
    <h3>Bar chart: Payment by type</h3>
</div>


<div id="bar-chart-payment-by-total">
    <h3>Bar Chart: Payment by total</h3>
</div>

<div id="line-chart-payment-over-time">
    <h3>Line Chart: Payment over Time</h3>
</div>
** Aug 28 in NYC <2017-08-28 Mon>            :day:
*** TODO IR Steel Discussion
*** TODO Bentler
*** DONE DC.js
*** TODO Crossfilter dimension and group review
*** TODO Senmantic UI
*** TODO Dashboard WIP
** Aug 29 in NYC <2017-08-29 Tue>
*** IR 
**** TODO Compile all grade benchmarks: DDS and EDDS
**** TODO Check the AV benchmarks
**** TODO Only include public pricebook if it's lower than IR prices
**** 
** Aug 30 in NYC <2017-08-30 Wed>            :day:
*** IR
*** Bentler
*** Dashboard
*** VBox set up
1. Device -> Insert Guest CD image
2. Open terminal
3. sudo sh ./VBoxLinuxAdditions.run
------------------------------------
1. Sharebox
2. Add sharefolder
3. sudo usermod -a -G vboxsf isaac
** Aug 31 in NYC <2017-08-31 Thu>            :day:
*** IR
**** Finalize
**** Call
*** Bentler
**** Draft
* 2017-Sep-log
** Sep 5 in NYC <2017-09-05 Tue>             :day:
*** D3
*** Web
